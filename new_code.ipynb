{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7176b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "import fitz\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"Tesseract-OCR\\\\tesseract.exe\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2a7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading block extractor........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\spsoft/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-5-3 Python-3.9.13 torch-1.13.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\spsoft\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\spsoft/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading feature extractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-5-3 Python-3.9.13 torch-1.13.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\spsoft\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 157 layers, 7029004 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# trained yolov5 model to extract individual cell from the cells group image\n",
    "print('loading block extractor........')\n",
    "yolo_block = {'path':'block.pt', 'force_reload':True}\n",
    "model_block = torch.hub.load('ultralytics/yolov5', 'custom', **yolo_block) \n",
    "\n",
    "# trained yolov5 model to extract features from the cell\n",
    "print('loading feature extractor')\n",
    "yolo_feature = {'path':'feature.pt', 'force_reload':True}\n",
    "model_feature = torch.hub.load('ultralytics/yolov5', 'custom', **yolo_feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_values = ['temp/pdf_1.png', 'temp/pdf_3.png', 'temp/pdf_8.png', 'temp/pdf_4.png']\n",
    "# order = {'temp/pdf_3.png': 1, 'temp/pdf_1.png': 0, 'temp/pdf_8.png': 3, 'temp/pdf_4.png': 2}\n",
    "\n",
    "# sorted_list = sorted(list_values, key=lambda x: order[x])\n",
    "# print(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "444cbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting pdf to image using PyMuPDF\n",
    "def pdf_image(path, image_path):\n",
    "    '''parameter path contains single_pdf_file location'''\n",
    "    dir_name, file_name = os.path.split(path)\n",
    "    img_name = os.path.splitext(file_name)[0]\n",
    "    zoom_x = 2.0  # horizontal zoom\n",
    "    zoom_y = 2.0  # vertical zoom\n",
    "    mat = fitz.Matrix(zoom_x, zoom_y)\n",
    "    #patht=\"/code/./coreservice/pdf\"\n",
    "    doc = fitz.open(path)\n",
    "    #os.chdir(patht)\n",
    "#     image_path = 'D:/poll/18022023/temp_image'\n",
    "    image_pages=[]\n",
    "    order = {}\n",
    "    for page in doc:  # iterate through the pages\n",
    "        pix = page.get_pixmap(matrix=mat)  # render page to an image\n",
    "        photo = \"{}_{}.png\".format(img_name, page.number)\n",
    "        photo_path = os.path.join(image_path, photo).replace('\\\\', '/')\n",
    "        order[photo_path] = page.number\n",
    "        pix.save(photo_path)\n",
    "        image_pages.append(photo_path)\n",
    "        print('image name:', photo_path)\n",
    "    \n",
    "    image_lst = sorted(image_pages, key = lambda x:order[x])\n",
    "    return image_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47111061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    text = text.replace('\\u200c','')\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace('౦','')\n",
    "    text = text.replace('స్తీ', 'స్త్రీ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d10d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ''
    }
   ],
   "source": [
    "files_path = r'test'\n",
    "img_path = r'temp_image'\n",
    "result_path = r'extracted_result'\n",
    "final_data = []\n",
    "block_dataframes = []\n",
    "feature_dataframes = []\n",
    "for direct, _, filenames in os.walk(files_path):\n",
    "    writer = pd.ExcelWriter(f'{result_path}\\\\extracted_data.xlsx', engine='xlsxwriter')\n",
    "    for filename in filenames:\n",
    "        name_file, ext = os.path.splitext(filename)\n",
    "        print('name:', name_file)\n",
    "        \n",
    "        if ext.lower() == '.pdf':\n",
    "            sheet_pdf = []         \n",
    "            pdf_path = os.path.join(direct, filename).replace('\\\\', '/')\n",
    "            print('pdf to image conversion started.......')\n",
    "            image_data = pdf_image(pdf_path, img_path)\n",
    "            print('............... image conversion completed')\n",
    "            if len(image_data) < 4:\n",
    "                print('no image data')\n",
    "                [os.remove(i) for i in image_data]\n",
    "                no_pages = pd.DataFrame([{'instruction':'Please check the given file it has to be atleast 4 pages'}])\n",
    "                no_pages.to_excel(f'{result_path}\\\\{name_file}.xlsx', index = False)\n",
    "                continue\n",
    "            else:\n",
    "                rmv_lst = image_data[:2] + [image_data[-1]]\n",
    "                [os.remove(i) for i in rmv_lst]\n",
    "                image_data = image_data[2:-1]         \n",
    "            img_cnt = 0\n",
    "            for image in image_data:                \n",
    "                img_cnt += 1\n",
    "                # block extractor\n",
    "                img = cv2.imread(image)\n",
    "                print('blocks extraction started.............')\n",
    "                blocks_image = model_block(img)\n",
    "                df = blocks_image.pandas().xyxy[0]\n",
    "#                 df = df.applymap(lambda x: int(x) if isinstance(x, float) else x)\n",
    "                df[['xmin', 'ymin', 'xmax', 'ymax']] = df[['xmin', 'ymin', 'xmax', 'ymax']].astype(int)\n",
    "                block_dataframes.append(df)\n",
    "                print('feature extraction started.......')\n",
    "                main_dir_name = os.path.splitext(os.path.split(image)[-1])[0]\n",
    "                main_dir = f'test_crop/{main_dir_name}_{img_cnt}'\n",
    "                os.mkdir(main_dir)\n",
    "                shutil.copy(image, main_dir)\n",
    "                cnt = 0\n",
    "                for xmin,ymin,xmax,ymax,thresh, annot_b in zip(df[\"xmin\"],df[\"ymin\"],df[\"xmax\"],df[\"ymax\"], df['confidence'], df['name']):\n",
    "                    cnt += 1\n",
    "                    block_image = img[ymin:ymax, xmin:xmax]\n",
    "                    try:\n",
    "                        sub_dir = f'{main_dir}/{annot_b}_{cnt}'\n",
    "                        os.mkdir(sub_dir)\n",
    "                        cv2.imwrite(f'{sub_dir}/{annot_b}.png', block_image)\n",
    "                    except:\n",
    "                        pass\n",
    "                    features_image = model_feature(block_image)\n",
    "                    feat_df = features_image.pandas().xyxy[0].sort_values(by = 'confidence', ascending = False)\n",
    "                    feat_df = feat_df.drop_duplicates(subset = 'name', keep = 'first')\n",
    "#                     feat_df = features_image.pandas().xyxy[0].applymap(lambda x: int(x) if isinstance(x, float) else x)\n",
    "                    feat_df[['xmin', 'ymin', 'xmax', 'ymax']] = feat_df[['xmin', 'ymin', 'xmax', 'ymax']].astype(int)\n",
    "                    feature_dataframes.append(feat_df)\n",
    "                    temp_data = {}\n",
    "                    for xmin_f, ymin_f, xmax_f,\\\n",
    "                    ymax_f,thresh_f, annot_f in zip(feat_df['xmin'], feat_df['ymin'],\\\n",
    "                                               feat_df['xmax'], feat_df['ymax'],feat_df['confidence'], feat_df['name']):\n",
    "                        feat_img = block_image[ymin_f:ymax_f, xmin_f:xmax_f]\n",
    "#                         print('feat image stored at:', f'D:/poll/pdf_data/test_crop/{name}_{cnt}/{name}.png')\n",
    "                        cv2.imwrite(f'{sub_dir}/{annot_f}.png', feat_img)\n",
    "                        temp_data[annot_f] = text_process(pytesseract.image_to_string(feat_img, lang = 'eng', config = '--psm 6'))\n",
    "#                         if annot_f == 'id':\n",
    "#                 ######################################################################\n",
    "#                             temp_data['Photo'] = Image.fromarray(block_image[ymax_f:, xmin_f:xmax_f])\n",
    "                    final_data.append(temp_data)\n",
    "                    sheet_pdf.append(temp_data)\n",
    "                    print(temp_data)\n",
    "                    print('-----------------------------------------------------')\n",
    "                os.remove(image)\n",
    "            print('----------done-------------')\n",
    "            result_pdf = pd.DataFrame(sheet_pdf)\n",
    "#             result_pdf = result_pdf[['sno','id','Name','Gender','Age','Gaurdian','HouseNo', 'Photo']]\n",
    "#             result_pdf.columns = ['Serial Number', 'Registration Number', 'Name',\n",
    "#                                  'Gender', 'Age', 'Guardian', 'House Number', 'Photo']\n",
    "            result_pdf = result_pdf[['sno','id','Name','Gender','Age','Gaurdian','HouseNo']]\n",
    "            result_pdf.columns = ['Serial Number', 'Registration Number', 'Name',\n",
    "                                 'Gender', 'Age', 'Guardian', 'House Number']\n",
    "            result_pdf.to_excel(writer, sheet_name = name_file, index = False)\n",
    "    writer.close()\n",
    "\n",
    "             \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21e0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
